{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78265783",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# set up\n",
    "from pathlib import Path\n",
    "from functools import cache\n",
    "from collections import deque\n",
    "ROOT = Path(__file__).resolve().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eaa3ff",
   "metadata": {},
   "source": [
    "## Day 7\n",
    "### Part 1\n",
    "- pretty standard traversal problem, we can model the grid as a graph and do BFS \n",
    "- find the starting point (i.e where `\"S\"` is), then kick off BFS from there\n",
    "- at a particular `(row, col)`\n",
    "    - if `grid[row][col] == \".\"`:\n",
    "        - we continue straight down, the \"neighbour\" in this case is `(row - 1, col)`\n",
    "    - else: (it's a splitter)\n",
    "        - increment the number of splits\n",
    "        - then you have 2 possible paths you should explore: `(row, col - 1)` and `(row, col + 1)`\n",
    "        - these 2 become your neighbours \n",
    "    - for each of the neighbour, check if they're inbound and **if they've been visited**\n",
    "        - the question was quite specific: \"the two splitters create a total of only three tachyon beams, since they are both dumping tachyons into the same place between them\"\n",
    "    - if the neighbour is good\n",
    "        - add them onto the queue, mark them as visited \n",
    "- at the end return the number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cb8c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def part1(input_path):\n",
    "    # the heavy lifting \n",
    "    with open(ROOT / input_path) as f: \n",
    "        input = f.read()\n",
    "    lines = [line.strip() for line in input.splitlines() if line.strip()]\n",
    "    return count_split(lines)\n",
    "\n",
    "def count_split(grid):\n",
    "    m, n = len(grid), len(grid[0])\n",
    "    queue, visited = deque([]), set()\n",
    "    start = find_start(grid)\n",
    "    visited.add(start)\n",
    "    queue.append(start)\n",
    "    \n",
    "    split_count = 0\n",
    "    while queue:\n",
    "        row, col = queue.popleft()\n",
    "        if grid[row][col] == \"^\":\n",
    "            # split \n",
    "            next_cells = [[row, col - 1], [row, col + 1]]\n",
    "            split_count += 1\n",
    "        else:\n",
    "            next_cells = [[row + 1, col]]\n",
    "\n",
    "        for nrow, ncol in next_cells:\n",
    "            if 0 <= nrow < m and 0 <= ncol < n and (nrow, ncol) not in visited:\n",
    "                visited.add((nrow,ncol))\n",
    "                queue.append((nrow,ncol))\n",
    "    return split_count\n",
    "\n",
    "def find_start(grid):\n",
    "    m, n = len(grid), len(grid[0])\n",
    "    queue, visited = deque([]), set()\n",
    "    for row in range(m):\n",
    "        for col in range(n):\n",
    "            if grid[row][col] == \"S\": \n",
    "                return (row, col)\n",
    "                visited.add((row,col))\n",
    "                queue.append((row,col))\n",
    "\n",
    "print(f\"The number of tachyon beam split in part 1 is {part1(\"input.txt\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28e47c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Part 2\n",
    "- this question kinda naturally lens itself to DFS since it has a DP shape \n",
    "- kick off DFS from `start`\n",
    "- the DFS function: this function counts the number of timelines starting at the given `(row, col)`\n",
    "    - parameters\n",
    "        - `row` and `col`: the current position on the grid \n",
    "    - base case \n",
    "        - if `row < 0 or row >= m or col < 0 or col >= n`, we're out of bounds \n",
    "            - meaning we've successfully explored a timeline/path, so this counts, return 1\n",
    "    - recursive case \n",
    "        - if it's a normal cell:\n",
    "            - the next cell to explore is the one directly below it \n",
    "            the result is just `dfs(row + 1, col)`\n",
    "        - it's a splitter cell\n",
    "            - there are 2 paths/timelines to explore: `(row, col - 1)` and `(row, col + 1)`\n",
    "            - need to explore both so `dfs(row, col - 1)` and `dfs(row, col + 1)`\n",
    "            - and since both will create their own timelines, sum up their results\n",
    "    - resources: if we cache this, then time complexity = space complexity = search space which is $O(n \\times m)$\n",
    "- kick off the DFS from start and return the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part2(input_path):\n",
    "    with open(ROOT / input_path) as f: \n",
    "        input = f.read()\n",
    "    lines = [line.strip() for line in input.splitlines() if line.strip()]\n",
    "    return count_timelines(lines)\n",
    "\n",
    "def count_timelines(grid):\n",
    "    m, n = len(grid), len(grid[0])\n",
    "    \n",
    "    @cache \n",
    "    def dfs(row, col):\n",
    "        if row < 0 or row >= m or col < 0 or col >= n:\n",
    "            return 1 # stop moving\n",
    "\n",
    "        num_timelines = 0\n",
    "        if grid[row][col] == \".\":\n",
    "            num_timelines = dfs(row + 1, col)\n",
    "        else:\n",
    "            num_timelines = dfs(row, col - 1) + dfs(row, col + 1)\n",
    "        return num_timelines\n",
    "\n",
    "    srow, scol = find_start(grid)\n",
    "    return dfs(srow, scol)\n",
    "    \n",
    "print(f\"The number of timelines in part 2 is {part2(\"input.txt\")}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
